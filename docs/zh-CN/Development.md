# ğŸ› ï¸ å¦‚ä½•åœ¨ VLMEvalKit ä¸­å®ç°ä¸€ä¸ªæ–°çš„ Benchmark æˆ–å¤šæ¨¡æ€æ¨¡å‹ï¼ˆVLMï¼‰

## å®ç°ä¸€ä¸ªæ–°çš„ benchmark

ç¤ºä¾‹ PR: **æ·»åŠ  Math-Vision Benchmark** ([#292](https://github.com/open-compass/VLMEvalKit/pull/292/files))

ç›®å‰åœ¨ VLMEvalKit ä¸­ï¼Œbenchmark ä»¥æ•°æ®é›†ç±»çš„å½¢å¼å‘ˆç°ï¼Œå½“ä½ æ–°å¢ä¸€ä¸ª benchmark æ—¶ï¼Œä½ å¯ä»¥é€‰æ‹©å¤ç”¨ç°æœ‰çš„æ•°æ®é›†ç±» (å¦‚å•é€‰é¢˜ benchmark å¯å¤ç”¨ `ImageMCQDataset`)ï¼Œæˆ–æ˜¯å®ç°æ–°çš„æ•°æ®é›†ç±»ã€‚ä½ çš„æ•°æ®é›†ç±»å¿…é¡»æ”¯æŒä»¥ä¸‹ä¸¤ç§æ–¹æ³• (å¤ç”¨çˆ¶ç±»æˆ–è‡ªè¡Œå®ç°):

- `build_prompt(self, line)`: æ–¹æ³•è¾“å…¥ `line` ç±»å‹ä¸º int (å¯¹åº”æ•°æ® index) æˆ– `pd.Series` (å¯¹åº”æ•°æ®åŸå§‹ record)ã€‚æ–¹æ³•è¾“å‡ºä¸€æ¡ `multi-modal message` ä½œä¸ºå¤šæ¨¡æ€æ¨¡å‹è¾“å…¥ï¼Œ`multi-modal message` æ˜¯ä¸€ä¸ªå›¾æ–‡äº¤é”™çš„åˆ—è¡¨ï¼Œå¦‚ä»¥ä¸‹æ ¼å¼ (ä¸€å›¾ä¸€æ–‡): `[dict(type='image', value=IMAGE_PTH), dict(type='text', value=prompt)]`ã€‚
- `evaluate(self, eval_file, **judge_kwargs)`: æ–¹æ³•è¾“å…¥ `eval_file` ä¸ºå¤šæ¨¡æ€æ¨¡å‹çš„é¢„æµ‹ç»“æœ (å¤šä»¥ `.xlsx` æ ¼å¼å­˜åœ¨)ï¼Œå¦‚ benchmark evaluation éœ€è¦å¤§è¯­è¨€æ¨¡å‹ (ä¸€èˆ¬ä¸º GPT) è¾…åŠ©ï¼Œåˆ™ `judge_kwargs` ä¼ å…¥å¤§è¯­è¨€æ¨¡å‹çš„å‚æ•°ã€‚æ–¹æ³•è¾“å‡º benchmark çš„è¯„æµ‹ç»“æœï¼Œä»¥ `dict` æˆ– `pd.DataFrame` çš„å½¢å¼ã€‚

ä»¥ä¸‹ï¼Œæˆ‘ä»¬ç®€è¿°æ–°å¢æ•°æ®é›†çš„é€šå¸¸æ­¥éª¤ï¼š

### 1. TSV æ•°æ®æ–‡ä»¶å‡†å¤‡ (å›¾æ–‡è¯„æµ‹é›†)

ç›®å‰ï¼Œæˆ‘ä»¬å°†æ¯ä¸€ä¸ª benchmark æ•°æ®é›†è®¾ç½®ä¸ºä¸€ä¸ªå•ç‹¬çš„ TSV æ–‡ä»¶ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ•°æ®æ–‡ä»¶å°†ä»æ•°æ®é›†å®šä¹‰çš„ `DATASET_URL` é“¾æ¥åœ°å€è‡ªåŠ¨ä¸‹è½½åˆ° `$LMUData` ä¸­ï¼ˆå¦‚æœæ²¡æœ‰æ˜ç¡®è®¾ç½®çš„è¯ï¼Œé»˜è®¤è·¯å¾„æ˜¯ `$HOME/LMUData`ï¼‰ã€‚ä½ å¯ä»¥å°†å‡†å¤‡å¥½çš„ TSV æ–‡ä»¶ä¸Šä¼ åˆ°ä¸€ä¸ªå¯ä¸‹è½½çš„åœ°å€ï¼ˆå¦‚ï¼šhuggingfaceï¼‰ï¼Œæˆ–å‘é€ç»™æˆ‘ä»¬ <opencompass@pjlab.org.cn>ï¼Œæˆ‘ä»¬å°†å¸®åŠ©ä¸Šä¼ æ•°æ®é›†åˆ°æœåŠ¡å™¨ä¸­ã€‚æ­¤å¤–ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨ç¯å¢ƒå˜é‡ä¸­è‡ªå®šä¹‰è®¾ç½®ä¸‹è½½è·¯å¾„ `LMUData=/path/to/your/data`ã€‚

TSV æ–‡ä»¶ä¸­çš„å†…å®¹ç»„æˆä¸ºï¼š

| æ•°æ®é›†åç§° \ å­—æ®µ  | index | image | image_path | question | hint | multi-choice<br>options | answer | category | l2-category | split |
| ---------------------- | ----- | ----- | ---------- | -------- | ---- | ----------------------- | ------ | -------- | ----------- | ----- |
| MMBench_DEV_[CN/EN]    | âœ…     | âœ…     |            | âœ…        | âœ…    | âœ…                       | âœ…      | âœ…        | âœ…           | âœ…     |
| MMBench_TEST_[CN/EN]   | âœ…     | âœ…     |            | âœ…        | âœ…    | âœ…                       |        | âœ…        | âœ…           | âœ…     |
| CCBench                | âœ…     | âœ…     |            | âœ…        |      | âœ…                       | âœ…      | âœ…        |             |       |
| SEEDBench_IMG          | âœ…     | âœ…     |            | âœ…        |      | âœ…                       | âœ…      | âœ…        |             |       |
| MME                    | âœ…     | âœ…     |            | âœ…        |      |                         | âœ…      | âœ…        |             |       |
| MMVet                  | âœ…     | âœ…     |            | âœ…        |      |                         | âœ…      | âœ…        |             |       |
| MMMU_DEV_VAL           | âœ…     | âœ…     | âœ…          | âœ…        |      | âœ…                       | âœ…      | âœ…        | âœ…           | âœ…     |
| COCO_VAL               | âœ…     | âœ…     |            |          |      |                         | âœ…      |          |             |       |
| OCRVQA_[TEST/TESTCORE] | âœ…     | âœ…     |            | âœ…        |      |                         | âœ…      |          |             |       |
| TextVQA_VAL            | âœ…     | âœ…     |            | âœ…        |      |                         | âœ…      |          |             |       |
| VCR_[EN/ZH]\_[EASY/HARD]_[ALL/500/100]            | âœ…     | âœ…     |            | âœ…        |      |                         | âœ…      |          |             |       |

<div align="center"><b>è¡¨ 1. æ”¯æŒçš„æ•°æ®é›†çš„ TSV å­—æ®µã€‚</b></div>

**TSV ä¸­å¿…é¡»å­—æ®µçš„ä»‹ç»ï¼š**

- **index:** ä¸€ä¸ªæ•´æ•°ï¼Œ`tsv` ä¸­æ¯ä¸€è¡Œçš„å”¯ä¸€æ ‡è¯†
- **image:** å›¾ç‰‡çš„ base64 ç¼–ç ï¼Œä½ å¯ä»¥ä½¿ç”¨ `vlmeval/smp/vlm.py` ä¸­å®ç°çš„APIè¿›è¡Œç¼–ç å’Œè§£ç ï¼š
    - ç¼–ç ï¼š`encode_image_to_base64`ï¼ˆå¯¹äºPIL Imageï¼‰/ `encode_image_file_to_base64`ï¼ˆå¯¹äºå›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼‰
    - è§£ç ï¼š`decode_base64_to_image`ï¼ˆå¯¹äºPIL Imageï¼‰/ `decode_base64_to_image_file`ï¼ˆå¯¹äºå›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼‰
- **question:** é’ˆå¯¹å›¾åƒæ‰€æå–å‡ºçš„é—®é¢˜ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²
- **answer:** é—®é¢˜çš„ç­”æ¡ˆï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼ŒTest é›†å¯ç¼ºå¤±è¿™ä¸€å­—æ®µ

### 2. è‡ªå®šä¹‰æ•°æ®é›†çš„ prompt æ„å»º

`ImageBaseDataset` å®šä¹‰äº†é»˜è®¤çš„ prompt æ ¼å¼ã€‚å¦‚æœéœ€è¦é’ˆå¯¹æ•°æ®é›†æ·»åŠ  promptï¼Œæˆ–ç»™æ¨¡å‹è¾“å…¥ `Interleave` çš„æ•°æ®æ ¼å¼ï¼Œå¯ä»¥é€šè¿‡ `build_prompt(line)` å‡½æ•°å®ç°ã€‚è¯¥å‡½æ•°è¾“å…¥ä¸ºï¼Œæ¯æ¬¡ç»™å®š TSV æ–‡ä»¶ä¸­çš„ä¸€è¡Œï¼ŒåŒ…å« index, image, question ç­‰å†…å®¹ä½œä¸º lineã€‚è¯¥å‡½æ•°å°†è¿”å›ä¸€ä¸ªå¤šæ¨¡æ€æ¶ˆæ¯ `msg` çš„å­—å…¸åˆ—è¡¨ `[dict(type='image', value=IMAGE_PTH), dict(type='text', value=prompt)]`ï¼ŒåŒ…æ‹¬å›¾ç‰‡è·¯å¾„å’Œå°†è¢«è¾“å…¥åˆ° VLMs çš„æ–‡æœ¬ promptã€‚å¯¹äº interleave ç±»å‹è¾“å…¥ï¼Œå¯ä»¥ç›´æ¥å°†å›¾ç‰‡è·¯å¾„çš„å­—å…¸æ”¾ç½®åˆ° image token ä½ç½®ã€‚

### 3. è‡ªå®šä¹‰æ•°æ®é›†çš„æŒ‡æ ‡å®ç°

å¢åŠ å¯¹ benchmark çš„è¯„æµ‹éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªè¯¥æ•°æ®é›†çš„ class å¯¹è±¡ï¼Œä»è€Œå®ç°æ•°æ®é›†çš„æŒ‡æ ‡è®¡ç®—ã€‚å›¾æ–‡å¤šæ¨¡æ€æ•°æ®é›†å‡ç»§æ‰¿è‡ª `vlmeval/dataset/image_base.py` ä¸­çš„ `ImageBaseDataset` å¯¹è±¡ã€‚å…¶ä¸­ `TYPE` å®šä¹‰äº†æ•°æ®é›†çš„ç±»å‹ï¼›`DATASET_URL` ä¸ºæ•°æ®é›†çš„ä¸‹è½½åœ°å€ï¼›`DATASET_MD5` ä¸ºæ•°æ®é›†æ–‡ä»¶çš„ md5 ä¸€è‡´æ€§ç¼–ç æ£€æŸ¥ã€‚

åœ¨ class ä¸­**éœ€è¦å®ç°** `evaluate(eval_file, **judge_kwargs)` ç±»å‡½æ•°ï¼Œå¯¹è‡ªå®šä¹‰çš„æ•°æ®é›†ç»“æœè¿›è¡ŒæŒ‡æ ‡è®¡ç®—å’Œç»“æœè¾“å‡ºã€‚å‡½æ•°è¾“å…¥ `eval_file` ä¸ºæ¨¡å‹é¢„æµ‹ç»“æœ `{model_name}_{dataset}.xlsx` çš„è·¯å¾„ã€‚å¯ä»¥é€šè¿‡ `load(eval_file)` æ–‡ä»¶å°†å…¶è¯»å–ä¸º panda.DataFrames ç±»å‹ï¼Œå…¶ä¸­åŒ…å« index, question, answer, category, prediction ç­‰å­—æ®µã€‚`judge_kwargs` å‚æ•°å°†ä¼ é€’ä¸€ä¸ªè¯„æµ‹ç›¸å…³çš„å­—å…¸ï¼Œå¦‚ï¼šjudge æ¨¡å‹çš„åç§°ï¼Œapi è¯·æ±‚çº¿ç¨‹æ•°ç­‰ã€‚**å‡½æ•°çš„è¿”å›å€¼**ä¸ºè¯„ä¼°å®Œæˆçš„å‡†ç¡®åº¦ç­‰æŒ‡æ ‡ï¼Œå…¶æ ¼å¼ä¸ºç”± list ç»„æˆçš„å­—å…¸ï¼Œå¹¶ç»„ç»‡æˆ panda.DataFrames ç±»å‹ã€‚

## å®ç°ä¸€ä¸ªæ–°çš„æ¨¡å‹

ç¤ºä¾‹ PR: **æ”¯æŒ LLaVA-Next-Interleave** ([#294](https://github.com/open-compass/VLMEvalKit/pull/294))

**1. æ”¯æŒ `generate_inner` API (å¿…é¡»)**

ç°æœ‰æ‰€æœ‰çš„æ¨¡å‹éƒ½åœ¨ `vlmeval/vlm` ä¸­å®ç°ã€‚å¯¹äºä¸€ä¸ªæœ€åŸºæœ¬çš„æ¨¡å‹ï¼Œä½ çš„æ¨¡å‹ç±»**åº”è¯¥å®ç°æ–¹æ³•** `generate_inner(msgs, dataset=None)`ã€‚è¿™ä¸ªå‡½æ•°å°†å‘ VLM è¾“å…¥ä¸€ä¸ªå¤šæ¨¡æ€æ•°æ®ï¼Œå¹¶è¿”å› VLM çš„é¢„æµ‹ï¼ˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼‰ã€‚å¯é€‰å‚æ•° `dataset` å¯ä»¥ç”¨ä½œæ¨¡å‹åœ¨ä¸åŒæ¨ç†ç­–ç•¥ä¹‹é—´åˆ‡æ¢çš„æ ‡å¿—ã€‚

å…¶ä¸­å¤šæ¨¡æ€æ¶ˆæ¯ `msgs` æ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸æœ‰ä¸¤ä¸ªé”®ï¼šç±»å‹å’Œå€¼ï¼š
- `type`ï¼šæˆ‘ä»¬ç›®å‰æ”¯æŒä¸¤ç§ç±»å‹ï¼Œé€‰é¡¹æ˜¯ ["image", "text"]ã€‚
- `value`ï¼šå½“ç±»å‹ä¸º `text` æ—¶ï¼Œå€¼æ˜¯æ–‡æœ¬æ¶ˆæ¯ï¼ˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼‰ï¼›å½“ç±»å‹ä¸º `image` æ—¶ï¼Œå€¼å¯ä»¥æ˜¯å›¾åƒæ–‡ä»¶çš„æœ¬åœ°è·¯å¾„ï¼Œæˆ–è€…æ˜¯å›¾åƒçš„URLã€‚

> ç›®å‰ï¼Œä¸€ä¸ªå¤šæ¨¡æ€æ¶ˆæ¯å¯èƒ½åŒ…å«ä»»æ„äº¤é”™çš„å›¾åƒå’Œæ–‡æœ¬ã€‚å¦‚æœä½ çš„æ¨¡å‹ä¸æ”¯æŒè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æ¨èçš„åšæ³•æ˜¯å–ç¬¬ä¸€å¼ å›¾åƒå’Œè¿æ¥çš„æ–‡æœ¬æ¶ˆæ¯ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ã€‚ä½ å¯ä»¥åœ¨æ¨¡å‹çš„ class ä¸­è®¾ç½® `INTERLEAVE = False` å¹¶è°ƒç”¨ `self.message_to_promptimg(message, dataset=dataset)` å‡½æ•°æ¥è·å–ä½ çš„ prompt å’Œç¬¬ä¸€å¼ å›¾ç‰‡çš„åœ°å€ã€‚

ä¸€äº›å¤šæ¨¡æ€æ¶ˆæ¯çš„ä¾‹å­:

```python
IMAGE_PTH = 'assets/apple.jpg'
IMAGE_URL = 'https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/assets/apple.jpg'
msg1 = [
    dict(type='image', value=IMAGE_PTH),
    dict(type='text', value='What is in this image?')
]
msg2 = [
    dict(type='image', value=IMAGE_URL),
    dict(type='image', value=IMAGE_URL),
    dict(type='text', value='How many apples are there in these images?')
]
response = model.generate(msg1)
```

ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬è¿˜æ”¯æŒæ¥å—å­—ç¬¦ä¸²åˆ—è¡¨ä½œä¸ºè¾“å…¥ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯å›¾åƒè·¯å¾„è¿˜æ˜¯å›¾åƒ URLï¼Œå¹¶è‡ªåŠ¨å°†å…¶è½¬æ¢ä¸º `list[dict]` æ ¼å¼ï¼š

```python
IMAGE_PTH = 'assets/apple.jpg'
IMAGE_URL = 'https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/assets/apple.jpg'
msg1 = [IMAGE_PTH, 'What is in this image?']
msg2 = [IMAGE_URL, IMAGE_URL,  'How many apples are there in these images?']
response = model.generate(msg1)
```

**2. æ”¯æŒè‡ªå®šä¹‰æç¤ºè¯æ„å»º (å¯é€‰)**

æ­¤å¤–ï¼Œä½ çš„æ¨¡å‹å¯ä»¥é€šè¿‡å®ç°ä¸¤ä¸ªå¯é€‰æ–¹æ³•æ¥æ”¯æŒè‡ªå®šä¹‰æç¤ºæ„å»ºï¼š`use_custom_prompt(dataset)` å’Œ `build_prompt(line, dataset=None)`ã€‚

- `use_custom_prompt(dataset)` å°†è¿”å›ä¸€ä¸ªå¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºæ¨¡å‹æ˜¯å¦åº”ä½¿ç”¨è‡ªå®šä¹‰æç¤ºæ„å»ºç­–ç•¥ã€‚
- å¦‚æœ`use_custom_prompt(dataset)`è¿”å› Trueï¼Œ`build_prompt(line, dataset)` åº”è¯¥ä¸ºç›¸åº”çš„æ•°æ®é›†è¿”å›ä¸€ä¸ªè‡ªå®šä¹‰æ„å»ºçš„å¤šæ¨¡æ€æ¶ˆæ¯ï¼Œline æ•°æ®æ˜¯ä¸€ä¸ªåŒ…å«æ•°æ®æ ·æœ¬æ‰€éœ€ä¿¡æ¯çš„å­—å…¸ã€‚å¦‚æœ`use_custom_prompt(dataset)` è¿”å›Falseï¼Œåˆ™å°†ä½¿ç”¨é»˜è®¤çš„ prompt æ„å»ºç­–ç•¥ã€‚

**3. æ”¯æŒå¤šè½®å¯¹è¯ (å¯é€‰)**

ä½ å¯ä»¥é€šè¿‡æ”¯æŒ `chat_inner(message, dataset)` API ä¸ºä½ çš„æ¨¡å‹æ–°å¢å¤šè½®å¯¹è¯åŠŸèƒ½å¹¶å…¼å®¹å¤šè½®å¯¹è¯è¯„æµ‹ã€‚è¿™ä¸ª API è¾“å‡ºä¸€ä¸ªå­—ç¬¦ä¸²å‹å›å¤ï¼Œ`message` åŒ…å«ä¸€ä¸ªèŠå¤©è®°å½•çš„åˆ—è¡¨ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```python
# Assume msg1, msg2, msg3, ... are multi-modal messages following the previously described format
# `chat_inner` take the following chat history list as input:
message = [
    dict(role='user', content=msg1),
    dict(role='assistant', content=msg2),
    dict(role='user', content=msg3),
    dict(role='assistant', content=msg4),
	......
    dict(role='user', content=msgn),
]
# `message` should contain an odd number of chat utterances, the role of utterances should be interleaved "user" and "assistant", with the role of the last utterance to be "user".
# The chat function will call `chat_inner`
response = model.chat(message)
```

### ç¤ºä¾‹ PRsï¼š

- ä¸æ”¯æŒäº¤é”™çš„å›¾åƒå’Œæ–‡æœ¬ï¼Œä¸”ä¸ä½¿ç”¨è‡ªå®šä¹‰æç¤ºçš„VLMï¼š[[æ¨¡å‹] æ”¯æŒ glm-4v-9b](https://github.com/open-compass/VLMEvalKit/pull/221)
- æ”¯æŒäº¤é”™çš„å›¾åƒå’Œæ–‡æœ¬åŠè‡ªå®šä¹‰æç¤ºçš„VLMï¼š[æ·»åŠ  MiniCPM-Llama3-V-2.5](https://github.com/open-compass/VLMEvalKit/pull/205)
- VLM APIï¼š[ç‰¹å¾æ·»åŠ  glmv](https://github.com/open-compass/VLMEvalKit/pull/201)

## ä¸º VLMEvalKit è´¡çŒ®ä»£ç 

å¦‚æœä½ æƒ³ä¸º **VLMEvalKit** è´¡çŒ®ä»£ç ï¼Œè¯·åœ¨æäº¤PRä¹‹å‰è¿›è¡Œé¢„æäº¤æ£€æŸ¥ã€‚è¿™æœ‰åŠ©äºä¿æŒä»£ç æ•´æ´ã€‚

```bash
# åœ¨VLMEvalKitçš„ç›®å½•ä¸‹ï¼Œå®‰è£…é¢„æäº¤ hook:
pip install pre-commit
pre-commit install
pre-commit run --all-files
# ç„¶åæäº¤ä½ çš„ä»£ç ã€‚
```
